{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44c55205",
   "metadata": {},
   "source": [
    "# üçÖ Multiclass Tomato Disease Classification\n",
    "This notebook trains ResNet50, EfficientNet-B0, and DenseNet121 to classify tomato leaf images into one of eight categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed4628f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1Ô∏è‚É£ Install required packages\n",
    "pip install torch torchvision matplotlib pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f85740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2Ô∏è‚É£ Imports & GPU check\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(\"CUDA:\", torch.cuda.is_available(), \"Device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5613967e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3Ô∏è‚É£ Dataset viewing: count images per class & bar chart\n",
    "base = \"/workspace/datacentervision/Tomato-Village/Variant-a(Multiclass Classification)\"\n",
    "splits = [\"train\", \"val\", \"test\"]\n",
    "counts = {}\n",
    "for split in splits:\n",
    "    path = os.path.join(base, split)\n",
    "    for cls in os.listdir(path):\n",
    "        counts.setdefault(split, {})[cls] = len(os.listdir(os.path.join(path, cls)))\n",
    "\n",
    "# convert to DataFrame\n",
    "df_counts = pd.DataFrame(counts).T\n",
    "print(df_counts)\n",
    "\n",
    "# bar chart\n",
    "df_counts.plot(kind=\"bar\", figsize=(10,5))\n",
    "plt.title(\"Images per Class in train/val/test\")\n",
    "plt.xlabel(\"Dataset Split\"); plt.ylabel(\"Count\"); plt.xticks(rotation=0)\n",
    "plt.grid(axis=\"y\"); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f959bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4Ô∏è‚É£ Preprocessing & (unused) augmentation pipelines\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "])\n",
    "# safety augmentation (defined but not applied):\n",
    "aug_transform = transforms.Compose([\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomRotation(15)\n",
    "])\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd47fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5Ô∏è‚É£ DataLoaders\n",
    "batch_size = 32\n",
    "data_dirs = {split: os.path.join(base, split) for split in splits}\n",
    "datasets_dict = {\n",
    "    split: datasets.ImageFolder(data_dirs[split],\n",
    "        transform=(train_transform if split==\"train\" else val_transform))\n",
    "    for split in splits\n",
    "}\n",
    "loaders = {\n",
    "    split: DataLoader(datasets_dict[split], batch_size=batch_size, shuffle=(split==\"train\"), num_workers=4)\n",
    "    for split in splits\n",
    "}\n",
    "class_names = datasets_dict[\"train\"].classes\n",
    "num_classes = len(class_names)\n",
    "print(\"Classes:\", class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df47aa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6Ô∏è‚É£ Models to compare\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_constructors = {\n",
    "    \"ResNet50\":    lambda: models.resnet50(pretrained=True),\n",
    "    \"EfficientNetB0\": lambda: models.efficientnet_b0(pretrained=True),\n",
    "    \"DenseNet121\": lambda: models.densenet121(pretrained=True)\n",
    "}\n",
    "\n",
    "def build_model(name):\n",
    "    m = model_constructors[name]()\n",
    "    # replace classifier head\n",
    "    if \"resnet\" in name.lower():\n",
    "        m.fc = nn.Linear(m.fc.in_features, num_classes)\n",
    "    elif \"efficientnet\" in name.lower():\n",
    "        m.classifier[1] = nn.Linear(m.classifier[1].in_features, num_classes)\n",
    "    else:\n",
    "        m.classifier = nn.Linear(m.classifier.in_features, num_classes)\n",
    "    return m.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ab235b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7Ô∏è‚É£ Training & evaluation loops\n",
    "def train_one_epoch(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for imgs, labels in loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "    return running_loss / len(loader.dataset)\n",
    "\n",
    "def eval_model(model, loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss, correct = 0, 0\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * imgs.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            all_preds += preds.cpu().tolist()\n",
    "            all_labels += labels.cpu().tolist()\n",
    "    acc = correct / len(loader.dataset)\n",
    "    report = classification_report(all_labels, all_preds, target_names=class_names, output_dict=True)\n",
    "    confmat = confusion_matrix(all_labels, all_preds)\n",
    "    return running_loss/len(loader.dataset), acc, report, confmat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9a38ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8Ô∏è‚É£ Run experiments + Save models\n",
    "import os\n",
    "os.makedirs(\"saved_models\", exist_ok=True)  # ensure folder exists\n",
    "\n",
    "results = {}\n",
    "epochs = 30\n",
    "for name in model_constructors:\n",
    "    print(f\"\\nüîÑ Training {name}\")\n",
    "    model = build_model(name)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    history = {\"train_loss\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        tl = train_one_epoch(model, loaders[\"train\"], criterion, optimizer)\n",
    "        vl, vacc, _, _ = eval_model(model, loaders[\"val\"], criterion)\n",
    "        print(f\" {name} Epoch {epoch+1}/{epochs}: train_loss={tl:.4f}, val_loss={vl:.4f}, val_acc={vacc:.4f}\")\n",
    "        history[\"train_loss\"].append(tl)\n",
    "        history[\"val_loss\"].append(vl)\n",
    "        history[\"val_acc\"].append(vacc)\n",
    "\n",
    "    # ‚úÖ Final test evaluation\n",
    "    test_loss, test_acc, test_report, test_confmat = eval_model(model, loaders[\"test\"], criterion)\n",
    "\n",
    "    # ‚úÖ Save trained model to results + disk\n",
    "    results[name] = {\n",
    "        \"model\": model,\n",
    "        \"history\": history,\n",
    "        \"test_loss\": test_loss,\n",
    "        \"test_acc\": test_acc,\n",
    "        \"report\": test_report,\n",
    "        \"confmat\": test_confmat\n",
    "    }\n",
    "\n",
    "    save_path = f\"saved_models/{name}.pth\"\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"‚úÖ Model {name} saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11e173c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9Ô∏è‚É£ Plot Loss & Accuracy Curves for each model\n",
    "for name, res in results.items():\n",
    "    h = res[\"history\"]\n",
    "    epochs_range = range(1, epochs+1)\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(epochs_range, h[\"train_loss\"], label=\"train_loss\")\n",
    "    plt.plot(epochs_range, h[\"val_loss\"],   label=\"val_loss\")\n",
    "    plt.title(f\"{name} Loss\"); plt.xlabel(\"Epoch\"); plt.legend(); plt.grid(True)\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(epochs_range, h[\"val_acc\"], label=\"val_acc\")\n",
    "    plt.title(f\"{name} Val Accuracy\"); plt.xlabel(\"Epoch\"); plt.legend(); plt.grid(True)\n",
    "    plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c193ee8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîü Print Evaluation Matrix & Confusion Matrix\n",
    "for name, res in results.items():\n",
    "    print(f\"\\nüèÅ {name} Test Accuracy: {res['test_acc']:.4f}  Test Loss: {res['test_loss']:.4f}\")\n",
    "    df_rep = pd.DataFrame(res[\"report\"]).T\n",
    "    print(\"Classification Report:\\n\", df_rep.round(3))\n",
    "    # Confusion matrix heatmap\n",
    "    plt.figure(figsize=(6,5))\n",
    "    cm = res[\"confmat\"]\n",
    "    plt.imshow(cm, interpolation='nearest')\n",
    "    plt.title(f\"{name} Confusion Matrix\"); plt.colorbar()\n",
    "    tick_marks = np.arange(num_classes)\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    plt.ylabel('True label'); plt.xlabel('Predicted label')\n",
    "    plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e10171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1Ô∏è‚É£1Ô∏è‚É£ Summary comparison table\n",
    "summary = []\n",
    "for name, res in results.items():\n",
    "    acc = res[\"test_acc\"]\n",
    "    loss = res[\"test_loss\"]\n",
    "    m_f1 = res[\"report\"][\"accuracy\"]\n",
    "    summary.append([name, acc, loss, m_f1])\n",
    "df_summary = pd.DataFrame(summary, columns=[\"Model\",\"Test Acc\",\"Test Loss\",\"Overall Acc\"]).set_index(\"Model\")\n",
    "print(df_summary.round(3))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
