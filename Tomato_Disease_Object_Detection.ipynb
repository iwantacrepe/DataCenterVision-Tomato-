{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "478a8227",
   "metadata": {},
   "source": [
    "# üõ∞Ô∏è YOLOv10 Tomato Disease Object Detection\n",
    "YOLOv10x is used to detect and localize tomato leaf diseases using bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89017b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Ultralytics which now includes YOLOv10 support\n",
    "pip install ultralytics --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528993e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU and environment\n",
    "import torch, os, yaml\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fcad2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set base directory\n",
    "base_dir = '/workspace/datacentervision/Tomato-Village/Variant-c(Object Detection)'\n",
    "\n",
    "# Define your class labels\n",
    "class_names = [\n",
    "    'Early_blight', 'Healthy', 'Late_blight', 'Leaf Miner',\n",
    "    'Magnesium Deficiency', 'Nitrogen Deficiency',\n",
    "    'Pottassium Deficiency', 'Spotted Wilt Virus'\n",
    "]\n",
    "\n",
    "# Create data.yaml\n",
    "data_cfg = {\n",
    "    'train': os.path.join(base_dir, 'train', 'images'),\n",
    "    'val': os.path.join(base_dir, 'val', 'images'),\n",
    "    'nc': len(class_names),\n",
    "    'names': class_names\n",
    "}\n",
    "\n",
    "with open('data.yaml', 'w') as f:\n",
    "    yaml.dump(data_cfg, f)\n",
    "\n",
    "print(\"‚úî data.yaml created:\")\n",
    "print(yaml.dump(data_cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211994d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "train_imgs = glob(os.path.join(data_cfg['train'], '*.*'))\n",
    "val_imgs = glob(os.path.join(data_cfg['val'], '*.*'))\n",
    "print(f\"Train Images: {len(train_imgs)}\")\n",
    "print(f\"Val Images:   {len(val_imgs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9bace8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_pascal(img_path, xml_path):\n",
    "    img = Image.open(img_path)\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    plt.figure(figsize=(6,6)); plt.imshow(img); ax = plt.gca()\n",
    "    for obj in root.findall('object'):\n",
    "        name = obj.find('name').text\n",
    "        bnd = obj.find('bndbox')\n",
    "        x1, y1 = int(bnd.find('xmin').text), int(bnd.find('ymin').text)\n",
    "        x2, y2 = int(bnd.find('xmax').text), int(bnd.find('ymax').text)\n",
    "        ax.add_patch(plt.Rectangle((x1,y1), x2-x1, y2-y1, edgecolor='lime', fill=False, lw=2))\n",
    "        ax.text(x1, y1-10, name, color='white', bbox=dict(facecolor='red', alpha=0.5))\n",
    "    plt.axis('off'); plt.show()\n",
    "\n",
    "# Example\n",
    "sample_img = train_imgs[0]\n",
    "sample_xml = os.path.join(base_dir, 'train', 'pascal_voc', os.path.basename(sample_img).replace('.jpg', '.xml'))\n",
    "show_pascal(sample_img, sample_xml)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20920c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "\n",
    "aug_pipeline = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.3),\n",
    "    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=15, p=0.5)\n",
    "], bbox_params=A.BboxParams(format='yolo', label_fields=['labels']))\n",
    "\n",
    "print(\"Augmentation pipeline ready (not applied during YOLO training)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc2dad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO('yolov10x.pt')  # Use the best (largest) variant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce66ddcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(\n",
    "    data='data.yaml',\n",
    "    epochs=60,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    project='runs/train',\n",
    "    name='yolov10-tomato',\n",
    "    save=True,\n",
    "    device=0  # or 'cuda'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5713acca",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.trainer.metrics\n",
    "plt.plot(results['epoch'], results['box_loss'], label='Box Loss')\n",
    "plt.plot(results['epoch'], results['cls_loss'], label='Class Loss')\n",
    "plt.plot(results['epoch'], results['obj_loss'], label='Obj Loss')\n",
    "plt.legend(); plt.title('Training Losses'); plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.grid(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1c7a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_results = model.val()\n",
    "print(f\"Validation Results:\\n mAP50: {val_results.box.map[0]:.4f} | mAP50-95: {val_results.box.map:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f03aec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(source=base_dir + \"/val/images\", conf=0.25, save=True)\n",
    "print(\"‚úÖ Inference complete. Annotated results saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc57139",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.export(format='onnx')\n",
    "model.export(format='torchscript')\n",
    "print(\"Model exported to ONNX and TorchScript formats.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
